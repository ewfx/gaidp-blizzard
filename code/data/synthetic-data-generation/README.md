# ğŸš€ **Synthetic Data Generator for Regulatory Policy Documents**

## âœ… **Colab Notebook**

[ğŸ”— Open in Google Colab](https://colab.research.google.com/drive/1gyh8qXfZnLNVgqUQqOujJBCIxNs7k3vO?usp=sharing)

<br/>

## ğŸ“Œ Summary

The Synthetic Data Generator is designed to **generate synthetic question-answer datasets** using **regulatory policy PDFs**. It extracts text from PDFs, **embeds the content**, generates **evolved questions** using an LLM (GPT-3.5-turbo), and stores the generated synthetic dataset in an **Excel file**.

<br/>

## ğŸŒŠ Flow

ğŸ”¹ This script **automates** the creation of question-answer datasets for regulatory policy documents.  
ğŸ”¹ Uses **AI-driven evolution** to make synthetic questions more complex.  
ğŸ”¹ Stores structured **context-aware Q&A pairs** in an **Excel file for further analysis**.  
ğŸ”¹ Can be expanded by adding **retrieval optimizations (FAISS)** or **more evolution templates**.

```mermaid
graph TD
  A[Start] --> B[Install Dependencies]
  B --> C[Set API Key & Mount Drive]
  C --> D[Load & Extract PDF Text]
  D --> E[Split Text into Chunks]
  E --> F[Generate Embeddings]

  F --> G[Select Random Reference Chunk]
  G --> H[Compute Cosine Similarity]
  H --> I[Select Top 5 Similar Chunks as Context]

  I --> J[Apply Evolution Templates]
  J --> K[Generate Evolved Question]
  K --> L[Generate Answer using LLM]

  L --> M[Store in Synthetic Dataset]
  M --> N[Save Data to Excel]
  N --> O[End]
```

<br/>

## ğŸ› ï¸ Technology Used

- **ğŸ“œ PyMuPDF** â€“ Extracts text from PDFs.
- **ğŸ§  OpenAI GPT-3.5-turbo** â€“ Generates questions and answers.
- **ğŸ“ LangChain & Sentence Transformers** â€“ Handles embeddings and text processing.
- **ğŸ“Š Pandas & OpenPyXL** â€“ Stores the dataset in an Excel sheet.

<br/>

## ğŸ—ï¸ Implementation Steps with Explanation

### ğŸ”¹ 1. Install Dependencies

The script installs necessary Python libraries using `pip install`.

### ğŸ”¹ 2. Set Up OpenAI API Key

- The API key is stored in an environment variable to interact with OpenAI models.

### ğŸ”¹ 3. Mount Google Drive (Colab Only)

- Mounts Google Drive to access policy PDFs stored in a folder.

### ğŸ”¹ 4. Load PDF Documents & Extract Text

- Uses **PyMuPDFLoader** to read the **policy PDFs**.
- The **TokenTextSplitter** splits the extracted text into **manageable chunks**.

### ğŸ”¹ 5. Generate Text Embeddings

- Uses **OpenAIEmbeddings** to convert text chunks into **vector representations**.
- These embeddings help in **semantic similarity matching** later.

### ğŸ”¹ 6. Select Context Using Similarity Search

- A **random chunk** is picked as a reference.
- The script calculates **cosine similarity** between the reference and other embeddings.
- The **top 5 similar chunks** are selected as context.

### ğŸ”¹ 7. Generate Synthetic Questions via Prompt Engineering

- Uses **three templates** to evolve the question:
  1. **Multi-Context** â€“ Requires multiple context pieces for answering.
  2. **Reasoning-Based** â€“ Demands multi-step logical reasoning.
  3. **Hypothetical Scenario** â€“ Creates a scenario-based question.
- A **random template** is applied **three times** for evolution.
- The final **evolved query** is generated.

### ğŸ”¹ 8. Generate Expected Answer

- The **LLM (GPT-3.5-turbo)** generates an **expected answer** based on the question and selected context.

### ğŸ”¹ 9. Store in a Synthetic Dataset Object

- Uses **Pydanticâ€™s `BaseModel`** to structure the dataset (`query`, `expected_output`, and `context`).

### ğŸ”¹ 10. Save Data to Excel

- Uses **Pandas and OpenPyXL** to save the generated **question-answer pairs** in an **Excel sheet (`test_data.xlsx`)**.
- If the file **does not exist**, it creates a **new Excel file**.
- If the file **already exists**, it **appends the new data** without overwriting old entries.
