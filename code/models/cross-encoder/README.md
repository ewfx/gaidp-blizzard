# ğŸš€ **Cross-Encoder Pipeline for Reranking Regulatory Policy Queries**

## âœ… **Colab Notebook**

[ğŸ”— Open in Google Colab](https://colab.research.google.com/drive/1JY-zbNvT-ovB357F-3aMB07HqHSLrEbe)

<br/>

## ğŸ“Œ Summary

This **Cross-Encoder Pipeline** is designed to **retrieve and rerank relevant policy text chunks** for a given query. It first retrieves the **top 500 results from Pinecone**, then applies a **Cross-Encoder reranking** to return the most relevant **top 10 results**. The pipeline is useful for **policy compliance checks, legal document analysis, and regulatory retrieval tasks**.

NOTE: The test data generated by `synthetic-data-generation` is used here.

<br/>

## ğŸŒŠ Flow

ğŸ”¹ **Retrieves top-k matches** from Pinecone (vector search).  
ğŸ”¹ **Uses a Cross-Encoder model** to assign relevance scores to retrieved chunks.  
ğŸ”¹ **Sorts results by Cross-Encoder scores** and keeps only the most relevant ones.  
ğŸ”¹ **Trains the Cross-Encoder model** using a **synthetic dataset of question-answer pairs**.  
ğŸ”¹ Stores the **trained Cross-Encoder model** in Google Drive for future use.

```mermaid
graph TD
  A[Start] --> B[Install Dependencies]
  B --> C[Set API Keys & Mount Drive]
  C --> D[Load Training Data Excel]
  D --> E[Prepare Question-Answer Pairs]
  E --> F[Train Cross-Encoder Model]
  F --> G[Save Model]

  G --> H[Retrieve Top-500 Results from Pinecone]
  H --> I[Prepare Query-Chunk Pairs]
  I --> J[Apply Cross-Encoder Reranking]
  J --> K[Sort & Select Top 10 Results]
  K --> L[Output Final Ranked Chunks]
  L --> M[End]
```

<br/>

## ğŸ› ï¸ Technology Used

- **ğŸ§  Cross-Encoder (sentence-transformers)** â€“ Reranks document chunks for relevance.
- **ğŸ“œ Pinecone** â€“ Performs **vector similarity search** on stored regulatory text chunks.
- **ğŸ” HuggingFaceEmbeddings** â€“ Uses BAAI/bge-base-en-v1.5 to generate vector embeddings for queries.
- **ğŸ“Š Pandas** â€“ Handles Excel-based training datasets.

<br/>

## ğŸ—ï¸ Implementation Steps with Explanation

### ğŸ”¹ 1. Install Dependencies

The script installs required **Python libraries**:

```python
!pip install sentence-transformers langchain_huggingface langchain_pinecone pinecone-client
```

### ğŸ”¹ 2. Set Up Pinecone & Hugging Face Embeddings

- **Loads Pinecone API Key** and initializes the index.
- Uses **BAAI/bge-base-en-v1.5** from Hugging Face to **generate query embeddings**.

```python
from pinecone import Pinecone
from langchain_huggingface import HuggingFaceEmbeddings

pinecone_api_key = os.getenv("PINECONE_API_KEY")
pc = Pinecone(api_key=pinecone_api_key)
index = pc.Index("profilestore")

embedder = HuggingFaceEmbeddings(model_name='BAAI/bge-base-en-v1.5')
```

### ğŸ”¹ 3. Load Training Data & Prepare Pairs

- Loads two **Excel files** (`testdata1.xlsx`, `testdata2.xlsx`) and **combines them**.
- **Shuffles** answers to create **negative samples** for training.

```python
df1 = pd.read_excel(folder_path + "testdata1.xlsx")
df2 = pd.read_excel(folder_path + "testdata2.xlsx")

df = pd.concat([df1, df2], ignore_index=True)

shuffled_answers = df["Answer"].sample(frac=1, random_state=42).reset_index(drop=True)

positive_samples = list(zip(df["Question"], df["Answer"], [1.0] * len(df)))
negative_samples = list(zip(df["Question"], shuffled_answers, [0.0] * len(df)))

train_data = positive_samples + negative_samples
random.shuffle(train_data)
```

### ğŸ”¹ 4. Train the Cross-Encoder Model

- Uses **cross-encoder/ms-marco-MiniLM-L-6-v2** as the base model.
- **Trains** the model using **PyTorchâ€™s DataLoader**.
- **Saves** the trained model in Google Drive.

```python
from sentence_transformers import CrossEncoder, InputExample
from torch.utils.data import DataLoader

train_samples = [InputExample(texts=[str(q), str(a)], label=score) for q, a, score in train_data]
train_dataloader = DataLoader(train_samples, batch_size=8, shuffle=True)

model = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2')

model.fit(
    train_dataloader=train_dataloader,
    epochs=3,
    warmup_steps=100
)

model.save(folder_path + "CrossEncoderModel")
```

### ğŸ”¹ 5. Retrieve Top-500 Matches from Pinecone

- **Converts query** into a vector using Hugging Face embeddings.
- **Queries Pinecone** to fetch **top-500** relevant text chunks.

```python
query = "What does 'Schedule A' determine?"
query_vector = embedder.embed_query(query)
pinecone_results = index.query(vector=query_vector, top_k=500, include_metadata=True)
```

### ğŸ”¹ 6. Apply Cross-Encoder Reranking

- Uses the **trained Cross-Encoder** to rerank **retrieved chunks** based on relevance.
- Constructs **query-chunk pairs** and assigns relevance scores.

```python
query_chunk_pairs = [(query, "".join(doc["metadata"]["text"])) for doc in pinecone_results["matches"]]
cross_encoder_scores = model.predict(query_chunk_pairs)
```

### ğŸ”¹ 7. Sort & Select Top-10 Relevant Chunks

- Sorts retrieved chunks by **Cross-Encoder scores**.
- Selects **top 10 most relevant** chunks.

```python
reranked_results = sorted(
    zip(pinecone_results["matches"], cross_encoder_scores),
    key=lambda x: x[1], reverse=True
)[:10]
```

### ğŸ”¹ 8. Output Final Ranked Results

Prints the **top 10 most relevant policy text chunks** based on reranking.

```python
for res, score in reranked_results:
    print(f"Chunk: {res['metadata']['text']}, Score: {score}")
```

<br/>

## ğŸ”¥ **Why Use a Cross-Encoder for Reranking?**

âœ… **More Accurate**: Instead of relying purely on **vector search**, the **Cross-Encoder** evaluates **both query & document together**.  
âœ… **Context-Aware**: Unlike embeddings, which work on **vector distance**, the Cross-Encoder considers **word interactions** between the query and chunk.  
âœ… **Optimized Retrieval**: Instead of working on all 500 retrieved chunks, the **top 10 are reranked**, improving **precision**.
