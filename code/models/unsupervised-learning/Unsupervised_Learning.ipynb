{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas pyarrow fastparquet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yJf_BUuX-YJl",
        "outputId": "8fbb3bc8-e48e-4c59-e23f-1318f67d0f46"
      },
      "id": "yJf_BUuX-YJl",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.11/dist-packages (18.1.0)\n",
            "Collecting fastparquet\n",
            "  Downloading fastparquet-2024.11.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: cramjam>=2.3 in /usr/local/lib/python3.11/dist-packages (from fastparquet) (2.9.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from fastparquet) (2025.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from fastparquet) (24.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Downloading fastparquet-2024.11.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: fastparquet\n",
            "Successfully installed fastparquet-2024.11.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "folder_path = \"/content/drive/My Drive/GenAI/\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r7DYQR_L-Cdh",
        "outputId": "c4685c78-34b8-4d45-9eeb-c72caed5a9bc"
      },
      "id": "r7DYQR_L-Cdh",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Read a Parquet file\n",
        "dataset_path = folder_path + \"data/unsupervised learning/dataset.parquet\"\n",
        "print(os.path.exists(dataset_path))\n",
        "\n",
        "df = pd.read_parquet(dataset_path)  # Uses pyarrow or fastparquet\n",
        "\n",
        "# Display the first few rows\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lObe4bB5-aqY",
        "outputId": "4466a5a2-6a84-42a8-9138-bfa08b32c704"
      },
      "id": "lObe4bB5-aqY",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "           ssn            cc_num    first   last gender      city state  \\\n",
            "0  367-85-9826  4361337605230458  Kristie  Davis      F  Chandler    OK   \n",
            "1  367-85-9826  4361337605230458  Kristie  Davis      F  Chandler    OK   \n",
            "2  367-85-9826  4361337605230458  Kristie  Davis      F  Chandler    OK   \n",
            "3  367-85-9826  4361337605230458  Kristie  Davis      F  Chandler    OK   \n",
            "4  367-85-9826  4361337605230458  Kristie  Davis      F  Chandler    OK   \n",
            "\n",
            "     zip  city_pop                     job         dob      acct_num  \\\n",
            "0  74834      7590  Chief Strategy Officer  1987-06-12  349734538563   \n",
            "1  74834      7590  Chief Strategy Officer  1987-06-12  349734538563   \n",
            "2  74834      7590  Chief Strategy Officer  1987-06-12  349734538563   \n",
            "3  74834      7590  Chief Strategy Officer  1987-06-12  349734538563   \n",
            "4  74834      7590  Chief Strategy Officer  1987-06-12  349734538563   \n",
            "\n",
            "                          trans_num  trans_date trans_time   unix_time  \\\n",
            "0  c036244703adb9d5392f4027d9d4b38d  2021-07-31   02:30:01  1627678801   \n",
            "1  42f000b0b3b0ef534e5b8ef9ec1db13a  2021-08-01   22:37:41  1627837661   \n",
            "2  543037b1baf088961e58d00b705f4bcc  2021-08-01   23:02:09  1627839129   \n",
            "3  00a4e08643edebf9277c2967676f6a26  2021-08-01   22:27:24  1627837044   \n",
            "4  492c4412815306718f686fc5b459a285  2021-12-02   02:28:51  1638392331   \n",
            "\n",
            "         category     amt  is_fraud                merchant  \n",
            "0     grocery_pos  337.54         1           fraud_Kovacek  \n",
            "1   personal_care   21.13         1           fraud_Bradtke  \n",
            "2   personal_care   22.61         1     fraud_Kozey-Kuhlman  \n",
            "3  health_fitness   17.32         1             fraud_Hills  \n",
            "4        misc_pos   75.82         0  fraud_Kemmer-Buckridge  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ISOLATION FOREST\n",
        "Useful for fraud detection purposes and is unsupervised learning"
      ],
      "metadata": {
        "id": "e0Wgyod4E8vk"
      },
      "id": "e0Wgyod4E8vk"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import IsolationForest\n",
        "\n",
        "# Select relevant features\n",
        "features = [\"gender\", \"amt\", \"unix_time\", \"category\", \"merchant\", \"city_pop\"]\n",
        "df_selected = df[features]\n",
        "\n",
        "# Encode categorical features\n",
        "df_selected = pd.get_dummies(df_selected)\n",
        "\n",
        "# Train Isolation Forest\n",
        "# Assigning random state to give same results everytime\n",
        "model = IsolationForest(contamination=0.4, random_state=42)  # 2% expected fraud\n",
        "model.fit(df_selected)\n",
        "\n",
        "# Predict fraud scores (-1 = anomaly, 1 = normal)\n",
        "df[\"fraud_score\"] = model.predict(df_selected)\n",
        "df[\"fraud_detected_isoforest\"] = (df[\"fraud_score\"] == -1).astype(int)  # Convert to 0/1"
      ],
      "metadata": {
        "id": "3K0zXWyQ98kW"
      },
      "id": "3K0zXWyQ98kW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "date_str = \"2024-03-23 00:30:00\"\n",
        "unix = datetime.strptime(date_str, \"%Y-%m-%d %H:%M:%S\").timestamp()\n",
        "\n",
        "new_transaction = pd.DataFrame([{\n",
        "    \"gender\": \"M\",\n",
        "    \"amt\": 500,\n",
        "    \"unix_time\": unix,\n",
        "    \"category\": \"Entertainment ej eoijeo ijoeij oiejoij \",\n",
        "    \"merchant\": \"Amazon\",\n",
        "    \"city_pop\": 5000000000\n",
        "}])\n",
        "\n",
        "new_transaction_encoded = pd.get_dummies(new_transaction)\n",
        "\n",
        "# Ensure all columns match the training dataset\n",
        "missing_cols = set(df_selected.columns) - set(new_transaction_encoded.columns)\n",
        "\n",
        "missing_df = pd.DataFrame(0, index=new_transaction_encoded.index, columns=list(missing_cols))\n",
        "new_transaction_encoded = pd.concat([new_transaction_encoded, missing_df], axis=1)\n",
        "\n",
        "\n",
        "# Reorder columns to match training data\n",
        "new_transaction_encoded = new_transaction_encoded[df_selected.columns]"
      ],
      "metadata": {
        "id": "fTE9TnQ6CCle"
      },
      "id": "fTE9TnQ6CCle",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict fraud score (-1 = fraud, 1 = normal)\n",
        "fraud_score = model.predict(new_transaction_encoded)[0]\n",
        "\n",
        "# Convert to readable format\n",
        "fraud_detected = 1 if fraud_score == -1 else 0\n",
        "\n",
        "print(\"Fraud Detected:\", fraud_score, fraud_detected)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kj5C-2y1CPfA",
        "outputId": "3bc84661-ef1c-48ae-c693-e46b360d7431"
      },
      "id": "kj5C-2y1CPfA",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fraud Detected: -1 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "# Save the trained Isolation Forest model\n",
        "model_path = folder_path + \"data/unsupervised learning/isolation_forest_model.joblib\"\n",
        "print(os.path.exists(model_path))\n",
        "\n",
        "joblib.dump(model, model_path)\n",
        "print(\"Model saved successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UiCpZh49J3Q9",
        "outputId": "5ed846ca-7265-481e-dd5c-a299e2d97092"
      },
      "id": "UiCpZh49J3Q9",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False\n",
            "Model saved successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# AUTO ENCODER\n",
        "Deep learning unsupervised model"
      ],
      "metadata": {
        "id": "0SxMWNAXFFoY"
      },
      "id": "0SxMWNAXFFoY"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow keras"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ISRgqeuOEmu-",
        "outputId": "c56e56b6-c85e-4cf6-d531-3a1655a107fb"
      },
      "id": "ISRgqeuOEmu-",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.11/dist-packages (3.8.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.71.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.13.0)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras) (0.14.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Select relevant features for Autoencoder\n",
        "df_selected = df[features]\n",
        "\n",
        "# Encode categorical features\n",
        "df_selected = pd.get_dummies(df_selected)\n",
        "\n",
        "# Normalize numerical features\n",
        "scaler = StandardScaler()\n",
        "batch_size = 10000\n",
        "df_scaled_list = []\n",
        "\n",
        "for i in range(0, len(df_selected), batch_size):\n",
        "    batch = df_selected.iloc[i : i + batch_size]\n",
        "    df_scaled_list.append(scaler.fit_transform(batch))\n",
        "\n",
        "df_scaled = df_scaled_list[0]  # Start with the first batch\n",
        "\n",
        "for batch in df_scaled_list[1:]:\n",
        "    df_scaled = np.concatenate((df_scaled, batch), axis=0)  # Incrementally add batches"
      ],
      "metadata": {
        "id": "vrFsKsnDFYcc"
      },
      "id": "vrFsKsnDFYcc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Dense\n",
        "\n",
        "# Define input size\n",
        "input_dim = df_scaled.shape[1]\n",
        "\n",
        "# Build Autoencoder model\n",
        "input_layer = Input(shape=(input_dim,))\n",
        "encoded = Dense(8, activation=\"relu\")(input_layer)\n",
        "encoded = Dense(4, activation=\"relu\")(encoded)\n",
        "decoded = Dense(8, activation=\"relu\")(encoded)\n",
        "decoded = Dense(input_dim, activation=\"sigmoid\")(decoded)\n",
        "\n",
        "autoencoder = Model(input_layer, decoded)\n",
        "autoencoder.compile(optimizer=\"adam\", loss=\"mse\")\n",
        "\n",
        "# Train the autoencoder\n",
        "autoencoder.fit(df_scaled, df_scaled, epochs=50, batch_size=32, shuffle=True)\n"
      ],
      "metadata": {
        "id": "udKfLdv3FTdV"
      },
      "id": "udKfLdv3FTdV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reconstruct transactions\n",
        "reconstructed = autoencoder.predict(df_scaled)\n",
        "\n",
        "# Compute reconstruction errors\n",
        "mse = np.mean(np.abs(df_scaled - reconstructed), axis=1)\n",
        "\n",
        "# Set a threshold for fraud (e.g., top 5% of errors)\n",
        "threshold = np.percentile(mse, 99.6)\n",
        "\n",
        "# Detect fraud (1 = fraud, 0 = normal)\n",
        "df[\"fraud_detected_autoencoder\"] = (mse > threshold).astype(int)\n"
      ],
      "metadata": {
        "id": "OSgbtJcHFavh"
      },
      "id": "OSgbtJcHFavh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "similarity_percentage = (df[\"fraud_detected_isoforest\"] == df[\"fraud_detected_autoencoder\"]).mean() * 100\n",
        "print(f\"Similarity between Isolation Forest and Autoencoder fraud detection: {similarity_percentage:.2f}%\")"
      ],
      "metadata": {
        "id": "a0d25SvwGBYD"
      },
      "id": "a0d25SvwGBYD",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}